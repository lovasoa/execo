#!/usr/bin/env python

from __future__ import with_statement
import optparse, sys, time, os, logging, re, fileinput, commands
import execo, execo_g5k # http://graal.ens-lyon.fr/~mimbert/execo/doc/

connect_params = {'user': 'root'}
script_name = os.path.basename(__file__)
script_path = os.path.realpath(script_name)
script_dir = os.path.dirname(script_path)


def classify_hosts(hosts):
    sources = [ host for host in hosts if host.address.find(".lyon.") > -1 ]
    targets = [ host for host in hosts if host.address.find(".lyon.") == -1 ]
    return (sources, targets)


def check_enough_hosts(sources, num_sources_needed, targets, num_targets_needed, verbose = False):
    if len(sources) < num_sources_needed or len(targets) < num_targets_needed:
        if verbose:
            if len(sources) < num_sources_needed:
                print "   not enough source hosts"
            if len(targets) < num_targets_needed:
                print "   not enough target hosts"
        return False
    else:
        return True
        

def prepare_xp_check_enough_func(deployed_hosts, undeployed_hosts, num_sources):
    print "   intermediate check: %i deployed hosts, %i undeployed hosts" % (len(deployed_hosts), len(undeployed_hosts))
    (sources, targets) = classify_hosts(deployed_hosts)
    return check_enough_hosts(sources, num_sources, targets, 0)


def pprint_sources_targets(sources, targets):
    print "   %i source hosts: %s" % (len(sources), sources)
    print "   %i target hosts: %s" % (len(targets), targets)

def gen_traffic_and_capture(xp_name,
                            log_dir,
                            duration,
                            sources,
                            targets,
                            num_sources,
                            pktgen_packet_size):

    pass_name = "%i_sources-%i_packet_size" % (num_sources, pktgen_packet_size)
    log_dir = "%s/%s" % (log_dir, pass_name)
    os.makedirs(log_dir)
    pktgen_log = "/tmp/%s.%s.pktgen.log" % (xp_name, pass_name)
    capture_file = "/storage2/capture/%s.%s.pcap" % (xp_name, pass_name)
    capture_log = "/storage2/capture/%s.%s.capture.log" % (xp_name, pass_name)
    local_capture_log = "%s/capture.log" % (log_dir)
    local_router_log = "%s/router.log" % (log_dir)
    
    sources = sources[0:num_sources]
    targets = targets[0:num_sources]

    print
    print "-- traffic generation and capture with %i hosts, packet size %i, for %s" % (num_sources,
                                                                                       pktgen_packet_size,
                                                                                       execo.format_duration(duration))
    pprint_sources_targets(sources, targets)

    # prepare actions
    print "-- prepare actions"
    report = execo.Report(name = pass_name)

    script_copy = execo.Put(sources,
                            local_files = ("%s/config-pktgen" % (script_dir,),),
                            connexion_params = connect_params)
    pktgen_config = execo.Remote(sources,
                                 "./config-pktgen -c 0 -p %i config {{[host.address for host in targets]}}" % (pktgen_packet_size,),
                                 connexion_params = connect_params)
    pktgen_start = execo.Remote(sources,
                                "nohup ./config-pktgen -d 2 start %i > %s 2>&1 &" % (duration, pktgen_log),
                                connexion_params = connect_params)
    gargantua = execo.Host('gargantua')
    capture_start = execo.Remote([gargantua],
                                 "killall snf-capture ; nohup snf-capture/snf-capture -t%i -d 50 -w %s -s 52 -fnseclibpcap >%s 2>&1 &" % (int(duration / 20), capture_file, capture_log))
    capture_stop = execo.Remote([gargantua],
                                "killall snf-capture")
                                
    get_pktgen_logs = execo.Get(sources,
                                local_location = "%s/{{{host}}}" % (log_dir,),
                                remote_files = (pktgen_log,),
                                create_dirs = True,
                                connexion_params = connect_params)
    get_capture_logs = execo.Get([gargantua],
                                 local_location = local_capture_log,
                                 remote_files = (capture_log,),
                                 create_dirs = False)

    remove_captures = execo.Remote([gargantua],
                                   "rm -f %s %s" % (capture_file, capture_log))

    get_mirroring_counter_1 = execo.Remote([gargantua],
                                          "snmpget -Os -c public -v 2c little-ego 1.3.6.1.2.1.31.1.1.1.10.9001")
    get_mirroring_counter_2 = execo.Remote([gargantua],
                                          "snmpget -Os -c public -v 2c little-ego 1.3.6.1.2.1.31.1.1.1.10.9001")

    report.add([script_copy,
                get_pktgen_logs,
                get_capture_logs,
                pktgen_config,
                pktgen_start,
                capture_start,
                capture_stop,
                remove_captures,
                get_mirroring_counter_1,
                get_mirroring_counter_2])

    # copy needed scripts to nodes
    print "-- copy needed scripts to nodes"
    script_copy.run()

    # configure pktgen on sources
    print "-- configure pktgen on sources"
    pktgen_config.run()

    # start network traffic capture on gargantua
    print "-- start network traffic capture on gargantua"
    capture_start.run()

    # start pktgen on sources
    print "-- start pktgen on sources"
    pktgen_start.run()

    # sleep 1/20 of transfer time to make sure that all traffic have
    # begun and reached a stable state
    sleeptime = duration / 20.0
    print "-- sleep %s" % execo.format_duration(sleeptime)
    execo.sleep(sleeptime)

    # get lyon router mirroring interface counter
    print "-- retrieve lyon router mirroring interface counter at transfer start"
    out = get_mirroring_counter_1.run().processes()[0].stdout()
    mo = re.search('Counter64: (\d+)', out)
    if mo:
        counter1 = int(mo.group(1))
    else:
        counter1 = None
        print "   ERROR retrieving lyon router mirroring interface counter at transfer start"

    # sleep 9/10 of transfer time
    bw_measure_time = duration * .9
    print "-- sleep %s" % execo.format_duration(bw_measure_time)
    execo.sleep(bw_measure_time)
    
    # get lyon router mirroring interface counter
    print "-- retrieve lyon router mirroring interface counter at transfer end"
    out = get_mirroring_counter_2.run().processes()[0].stdout()
    mo = re.search('Counter64: (\d+)', out)
    if mo:
        counter2 = int(mo.group(1))
    else:
        counter2 = None
        print "   ERROR retrieving lyon router mirroring interface counter at transfer end"

    # sleep until the end of the transfers
    sleeptime = duration / 20.0 + 5.0
    print "-- sleep %s" % execo.format_duration(sleeptime)
    execo.sleep(sleeptime)

    # stop network traffic capture on gargantua
    print "-- stop network traffic capture on gargantua"
    capture_stop.run()

    # retrieve logs
    print "-- retrieve logs"
    get_pktgen_logs.start()
    get_capture_logs.start()
    get_pktgen_logs.wait()
    get_capture_logs.wait()

    # remove capture files on gargantua
    print "-- remove capture files on gargantua"
    remove_captures.run()

    # write router mirror link counters to log
    with open(local_router_log, "w") as routerlog:
        print >> routerlog, "ifOutOctets start = %s" % counter1
        print >> routerlog, "ifOutOctets end = %s" % counter2
        print >> routerlog, "interval = %f" % bw_measure_time
        if counter1 == None or counter2 == None:
            print >> routerlog, "bandwidth bits/s = 0.0 (ERROR)"
        else:
            if counter2 < counter1:
                # counter has wrapped
                delta = 0x10000000000000000 - counter1 + counter2
            else:
                delta = counter2 - counter1
            bitspersec = delta * 8.0 / bw_measure_time
            print >> routerlog, "bandwidth bits/s = %f" % bitspersec

    # print report
    print "-- results"
    print report.output(wide = True)

    return report

def main():

    # parse command line
    parser = optparse.OptionParser(
        usage = "usage: %prog <oargrid job id> <transfer duration in seconds> <list of num sources> <list of packet sizes>\n  (lists are comma separated)")
    (options, args) = parser.parse_args()
    if len(args) != 4:
        parser.print_help()
        sys.exit(1)
    job = int(args[0])
    transfer_duration = int(args[1])
    num_sources_list = []
    for num_sources in args[2].split(','):
        num_sources_list.append(int(num_sources))
    num_sources_list.sort()
    highest_num_sources = num_sources_list[-1]
    packet_size_list = []
    for packet_size in args[3].split(','):
        packet_size_list.append(int(packet_size))
    packet_size_list.sort(reverse = True)

    # configure logging
    t = time.localtime()
    formatted_time = time.strftime("%Y%m%d_%H%M%S", t)
    timezone = time.strftime("%Z", t)
    if timezone != "": formatted_time += "_" + timezone
    xp_name = "%s.%s" % (script_name, formatted_time,)
    log_dir = "%s/logs.%s" % (script_dir, xp_name)
    os.makedirs(log_dir)
    xp_log = open("%s/run.log" % (log_dir,), 'w')
    sys.stdout = xp_log
    sys.stderr = xp_log
    # update execo logger to these new stdout, stderr streams
    logger_handler = logging.StreamHandler(xp_log)
    execo.configuration['color_mode'] = False
    execo.set_log_level(logging.WARNING)

    # print infos about xp
    print "-- xp: %s" % (xp_name,)
    print "   command line: %s" % (" ".join(sys.argv),)
    print "   oargridjob = %s" % (job,)
    print "   oargridsub command line = oargridsub %s" % (commands.getoutput("oargridstat %s | sed -n 's/^cmd : \\(.*\\)$/\\1/p'" % (job,)),)
    print "   transfer duration = %s" % (transfer_duration,)
    print "   num sources = %s" % (num_sources_list,)
    print "   packet sizes = %s" % (packet_size_list,)
    print "   log dir = %s" % (log_dir,)
    print

    # wait job start and get nodes
    print "-- wait job start"
    execo_g5k.wait_oargrid_job_start(job)
    print "-- get job hosts"
    job_hosts = execo_g5k.get_oargrid_job_nodes(job)

    (sources, targets) = classify_hosts(job_hosts)

    pprint_sources_targets(sources, targets)

    print "-- check enough hosts"
    check_enough_hosts(sources,
                       highest_num_sources,
                       targets,
                       highest_num_sources,
                       verbose = True) or sys.exit("not enough hosts")

    # deploy needed hosts
    print "-- deploy hosts (at least %i sources and %i targets)" % (highest_num_sources, highest_num_sources)
    (deployed_hosts, error_hosts, all_hosts) = execo_g5k.prepare_deployed_xp(
        hosts = job_hosts,
        connexion_params = connect_params,
        #environment_name = 'lenny-x64-base',
        environment_file = '/home/lyon/mimbert/images/sid-x64-damien-1.0.13_091028.dsc',
        check_enough_func = lambda deployed_hosts, undeployed_hosts: prepare_xp_check_enough_func(deployed_hosts,
                                                                                                  undeployed_hosts,
                                                                                                  highest_num_sources))
    print "   %i undeployed hosts: %s" % (len(error_hosts), error_hosts)
    print "   %i deployed hosts: %s" % (len(deployed_hosts), deployed_hosts)
    (sources, targets) = classify_hosts(deployed_hosts)
    
    pprint_sources_targets(sources, targets)

    print "-- check enough hosts deployed (at least %i sources and %i targets)" % (highest_num_sources, highest_num_sources)
    check_enough_hosts(sources,
                       highest_num_sources,
                       targets,
                       0,
                       verbose = True) or sys.exit("not enough hosts")

    # run traffic generation and capture
    print "-- run traffic generation and capture"
    global_report = execo.Report()

    for num_sources in num_sources_list:
        for packet_size in packet_size_list:
            report = gen_traffic_and_capture(xp_name,
                                             log_dir,
                                             transfer_duration,
                                             sources,
                                             targets,
                                             num_sources,
                                             packet_size)
            global_report.add((report,))
    print global_report.output(wide = True)

    print "-- done"

main()
